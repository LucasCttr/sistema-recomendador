{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03539d43",
   "metadata": {},
   "source": [
    "# Sistema de recomendación con MovieLens 1M\n",
    "Este notebook  se basa en el entrenamiento y validacion de un modelo de filtrado colaborativo usando SVD sobre el dataset MovieLens 1M."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b7b3f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘ml-1m.zip’ already there; not retrieving.\n",
      "\n",
      "Archive:  ml-1m.zip\n"
     ]
    }
   ],
   "source": [
    "# Descargar y descomprimir MovieLens 1M\n",
    "!wget -nc https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "!unzip -n ml-1m.zip -d ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "510cfe0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1     1193       5  978300760\n",
       "1       1      661       3  978302109\n",
       "2       1      914       3  978301968\n",
       "3       1     3408       4  978300275\n",
       "4       1     2355       5  978824291"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Cargar ratings\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep='::', engine='python', names=['userId', 'movieId', 'rating', 'timestamp'])\n",
    "# Cargar películas\n",
    "movies = pd.read_csv('ml-1m/movies.dat', sep='::', engine='python', names=['movieId', 'title', 'genres'], encoding='latin-1')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8760d30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas de ratings: ['userId', 'movieId', 'rating', 'timestamp']\n",
      "Tipos de datos:\n",
      "userId       int64\n",
      "movieId      int64\n",
      "rating       int64\n",
      "timestamp    int64\n",
      "dtype: object\n",
      "Primeras filas:\n",
      "   userId  movieId  rating  timestamp\n",
      "0       1     1193       5  978300760\n",
      "1       1      661       3  978302109\n",
      "2       1      914       3  978301968\n",
      "3       1     3408       4  978300275\n",
      "4       1     2355       5  978824291\n"
     ]
    }
   ],
   "source": [
    "# Formato de la tabla ratings\n",
    "print('Columnas de ratings:', ratings.columns.tolist())\n",
    "print('Tipos de datos:')\n",
    "print(ratings.dtypes)\n",
    "print('Primeras filas:')\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ab374f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings por película (media, min, max): 269.88909875876953 1 3428\n",
      "Ratings por usuario (media, min, max): 165.5975165562914 20 2314\n"
     ]
    }
   ],
   "source": [
    "# Cantidad de ratings por película y por usuario\n",
    "print('Ratings por película (media, min, max):',\n",
    "      ratings['movieId'].value_counts().mean(),\n",
    "      ratings['movieId'].value_counts().min(),\n",
    "      ratings['movieId'].value_counts().max())\n",
    "print('Ratings por usuario (media, min, max):',\n",
    "      ratings['userId'].value_counts().mean(),\n",
    "      ratings['userId'].value_counts().min(),\n",
    "      ratings['userId'].value_counts().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73bf9586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de usuarios únicos: 6040\n",
      "Cantidad de películas únicas: 3706\n",
      "Formato de ratings (valores únicos): [1, 2, 3, 4, 5]\n",
      "Ejemplo de ratings: [5, 3, 3, 4, 5, 3, 5, 5, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "# Exploración inicial del dataset MovieLens 1M\n",
    "print('Cantidad de usuarios únicos:', ratings['userId'].nunique())\n",
    "print('Cantidad de películas únicas:', ratings['movieId'].nunique())\n",
    "print('Formato de ratings (valores únicos):', sorted(ratings['rating'].unique()))\n",
    "print('Ejemplo de ratings:', ratings['rating'].head(10).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8376b7",
   "metadata": {},
   "source": [
    "## Modelo SVD Tradicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "256b4209",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_373039/4187857497.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mtest_ratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'userId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_train_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     ]\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_filtered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'userId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mmovie\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'movieId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds_train_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/Proyectos/CIENCIADATOSPF/.venv_ml1m/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1559\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1560\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m         \u001b[0musing_cow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1563\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1564\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0musing_cow\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_single_block\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m                 \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_references\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/Proyectos/CIENCIADATOSPF/.venv_ml1m/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, other, method, **kwargs)\u001b[0m\n\u001b[1;32m   6286\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6287\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6288\u001b[0m                 \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6290\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"concat\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6291\u001b[0m             \u001b[0;31m# propagate attrs only if all concat arguments have the same attrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6293\u001b[0m                 \u001b[0;31m# all concatenate arguments have non-empty attrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# validación Split Data\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.sparse.linalg import svds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "cv_folds = 5\n",
    "kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "\n",
    "for train_idx, test_idx in kf.split(ratings):\n",
    "    train_ratings = ratings.iloc[train_idx]\n",
    "    test_ratings = ratings.iloc[test_idx]\n",
    "    \n",
    "    # Crear matriz usuario-película\n",
    "    train_matrix = train_ratings.pivot(index='userId', columns='movieId', values='rating')\n",
    "    \n",
    "    # CLAVE: Calcular medias SOLO sobre valores reales (ignorando NaN)\n",
    "    user_means = train_matrix.mean(axis=1).fillna(0)\n",
    "    \n",
    "    # Normalizar ANTES de rellenar\n",
    "    matrix_norm = train_matrix.sub(user_means, axis=0)\n",
    "    \n",
    "    # AHORA sí rellenar con 0 (representa \"desviación desconocida\")\n",
    "    matrix_norm_filled = matrix_norm.fillna(0).values\n",
    "    \n",
    "    # SVD\n",
    "    U, sigma, Vt = svds(matrix_norm_filled, k=20)\n",
    "    sigma = np.diag(sigma)\n",
    "    \n",
    "    # Reconstruir y desnormalizar\n",
    "    all_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_means.values.reshape(-1, 1)\n",
    "    \n",
    "    # Limitar predicciones al rango válido\n",
    "    all_predicted_ratings = np.clip(all_predicted_ratings, 1, 5)\n",
    "    \n",
    "    preds_train_df = pd.DataFrame(\n",
    "        all_predicted_ratings, \n",
    "        columns=train_matrix.columns, \n",
    "        index=train_matrix.index\n",
    "    )\n",
    "    \n",
    "    # Evaluar en test\n",
    "    test_filtered = test_ratings[\n",
    "        test_ratings['movieId'].isin(preds_train_df.columns) & \n",
    "        test_ratings['userId'].isin(preds_train_df.index)\n",
    "    ]\n",
    "    \n",
    "    preds = []\n",
    "    for _, row in test_filtered.iterrows():\n",
    "        user = row['userId']\n",
    "        movie = row['movieId']\n",
    "        pred = preds_train_df.loc[user, movie]\n",
    "        preds.append(pred)\n",
    "    \n",
    "    if len(preds) > 0:\n",
    "        rmse = np.sqrt(mean_squared_error(test_filtered['rating'], preds))\n",
    "        mae = mean_absolute_error(test_filtered['rating'], preds)\n",
    "        rmse_scores.append(rmse)\n",
    "        mae_scores.append(mae)\n",
    "\n",
    "print(f'RMSE promedio: {np.mean(rmse_scores):.4f}')\n",
    "print(f'MAE promedio: {np.mean(mae_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774a245d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SVD MANUAL - MÉTRICAS ADICIONALES\n",
      "============================================================\n",
      "Precision@10: 0.8250\n",
      "Recall@10:    0.5968\n",
      "Coverage:     0.9244 (92.44% del catálogo)\n",
      "F1-Score:     0.6926\n",
      "\n",
      "============================================================\n",
      "EJEMPLOS: PREDICCIONES VS RATINGS REALES\n",
      "============================================================\n",
      "Usuario    Película   Real     Predicho   Error   \n",
      "------------------------------------------------------------\n",
      "2271       3093       3.0      4.08       1.08    \n",
      "4455       2600       4.0      3.71       0.29    \n",
      "5964       3396       5.0      4.25       0.75    \n",
      "3591       3408       4.0      3.79       0.21    \n",
      "4909       1196       4.0      3.89       0.11    \n",
      "4024       1225       5.0      3.41       1.59    \n",
      "4772       908        4.0      4.23       0.23    \n",
      "3690       3044       3.0      2.99       0.01    \n",
      "4329       2762       5.0      4.08       0.92    \n",
      "2059       1617       3.0      3.51       0.51    \n",
      "4312       3256       3.0      3.52       0.52    \n",
      "3266       1103       5.0      4.37       0.63    \n",
      "3539       523        3.0      4.01       1.01    \n",
      "33         2664       5.0      3.74       1.26    \n",
      "1788       2291       3.0      4.09       1.09    \n",
      "3390       2080       5.0      4.20       0.80    \n",
      "4207       2262       3.0      4.19       1.19    \n",
      "2643       1092       3.0      3.53       0.53    \n",
      "937        3020       4.0      3.77       0.23    \n",
      "2601       2291       5.0      3.60       1.40    \n",
      "\n",
      "============================================================\n",
      "DISTRIBUCIÓN DE ERRORES\n",
      "============================================================\n",
      "Error promedio:      0.7583\n",
      "Error mediano:       0.6395\n",
      "Error máximo:        3.8865\n",
      "Desviación estándar: 0.5861\n",
      "\n",
      "Distribución de errores absolutos:\n",
      "  0.0 - 0.5:  80771 (40.38%)\n",
      "  0.5 - 1.0:  61495 (30.75%)\n",
      "  1.0 - 1.5:  35293 (17.65%)\n",
      "  1.5 - 2.0:  14362 ( 7.18%)\n",
      "  2.0 - 5.0:   8084 ( 4.04%)\n",
      "\n",
      "============================================================\n",
      "TOP 5 USUARIOS CON MEJOR/PEOR PREDICCIÓN\n",
      "============================================================\n",
      "\n",
      "Mejor predicción (menor error):\n",
      "  Usuario 3598: Error promedio = 0.0196 (13 ratings)\n",
      "  Usuario 5037: Error promedio = 0.0437 (17 ratings)\n",
      "  Usuario 4614: Error promedio = 0.0596 (6 ratings)\n",
      "  Usuario 2339: Error promedio = 0.0607 (7 ratings)\n",
      "  Usuario 283: Error promedio = 0.1429 (7 ratings)\n",
      "\n",
      "Peor predicción (mayor error):\n",
      "  Usuario 2432: Error promedio = 2.2580 (6 ratings)\n",
      "  Usuario 4761: Error promedio = 2.1243 (8 ratings)\n",
      "  Usuario 2982: Error promedio = 2.0776 (6 ratings)\n",
      "  Usuario 1270: Error promedio = 1.7710 (9 ratings)\n",
      "  Usuario 5828: Error promedio = 1.7480 (5 ratings)\n"
     ]
    }
   ],
   "source": [
    "# ========== MÉTRICAS ADICIONALES PARA SVD MANUAL ==========\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Configuración\n",
    "k_top = 10\n",
    "threshold = 3\n",
    "\n",
    "# Volver a ejecutar UN FOLD para obtener predicciones\n",
    "# (usamos el último fold del cross-validation anterior)\n",
    "train_ratings = ratings.iloc[train_idx]\n",
    "test_ratings = ratings.iloc[test_idx]\n",
    "\n",
    "# Crear matriz usuario-película\n",
    "train_matrix = train_ratings.pivot(index='userId', columns='movieId', values='rating')\n",
    "user_means = train_matrix.mean(axis=1).fillna(0)\n",
    "matrix_norm = train_matrix.sub(user_means, axis=0)\n",
    "matrix_norm_filled = matrix_norm.fillna(0).values\n",
    "\n",
    "# SVD\n",
    "U, sigma, Vt = svds(matrix_norm_filled, k=20)\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "# Reconstruir\n",
    "all_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_means.values.reshape(-1, 1)\n",
    "all_predicted_ratings = np.clip(all_predicted_ratings, 1, 5)\n",
    "\n",
    "preds_train_df = pd.DataFrame(\n",
    "    all_predicted_ratings, \n",
    "    columns=train_matrix.columns, \n",
    "    index=train_matrix.index\n",
    ")\n",
    "\n",
    "# Filtrar test\n",
    "test_filtered = test_ratings[\n",
    "    test_ratings['movieId'].isin(preds_train_df.columns) & \n",
    "    test_ratings['userId'].isin(preds_train_df.index)\n",
    "]\n",
    "\n",
    "\n",
    "# ========== FUNCIONES DE EVALUACIÓN ==========\n",
    "def precision_recall_at_k_manual(test_filtered, preds_df, k=10, threshold=3.5):\n",
    "    \"\"\"Calcula Precision@K y Recall@K para SVD manual\"\"\"\n",
    "    \n",
    "    # Agrupar por usuario\n",
    "    user_predictions = defaultdict(list)\n",
    "    \n",
    "    for _, row in test_filtered.iterrows():\n",
    "        user = row['userId']\n",
    "        movie = row['movieId']\n",
    "        true_rating = row['rating']\n",
    "        pred_rating = preds_df.loc[user, movie]\n",
    "        \n",
    "        user_predictions[user].append((pred_rating, true_rating))\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    for user, predictions in user_predictions.items():\n",
    "        # Ordenar por predicción descendente\n",
    "        predictions_sorted = sorted(predictions, key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        # Top-k\n",
    "        top_k = predictions_sorted[:k]\n",
    "        \n",
    "        # Relevantes en top-k\n",
    "        n_rel_and_rec_k = sum(1 for (_, true_r) in top_k if true_r >= threshold)\n",
    "        \n",
    "        # Total relevantes\n",
    "        n_rel = sum(1 for (_, true_r) in predictions if true_r >= threshold)\n",
    "        \n",
    "        # Precision y Recall\n",
    "        if k > 0:\n",
    "            precisions.append(n_rel_and_rec_k / k)\n",
    "        if n_rel > 0:\n",
    "            recalls.append(n_rel_and_rec_k / n_rel)\n",
    "    \n",
    "    return np.mean(precisions) if precisions else 0, np.mean(recalls) if recalls else 0\n",
    "\n",
    "\n",
    "def coverage_manual(test_filtered, preds_df, train_matrix, threshold=3.5):\n",
    "    \"\"\"Calcula coverage para SVD manual\"\"\"\n",
    "    \n",
    "    # Todas las películas en el dataset de entrenamiento\n",
    "    all_movies = set(train_matrix.columns)\n",
    "    \n",
    "    # Películas recomendadas (con predicción >= threshold)\n",
    "    recommended_movies = set()\n",
    "    \n",
    "    for _, row in test_filtered.iterrows():\n",
    "        user = row['userId']\n",
    "        movie = row['movieId']\n",
    "        pred_rating = preds_df.loc[user, movie]\n",
    "        \n",
    "        if pred_rating >= threshold:\n",
    "            recommended_movies.add(movie)\n",
    "    \n",
    "    coverage_score = len(recommended_movies) / len(all_movies) if len(all_movies) > 0 else 0\n",
    "    return coverage_score\n",
    "\n",
    "\n",
    "# ========== CALCULAR MÉTRICAS ==========\n",
    "print(\"=\" * 60)\n",
    "print(\"SVD MANUAL - MÉTRICAS ADICIONALES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "precision, recall = precision_recall_at_k_manual(test_filtered, preds_train_df, k=k_top, threshold=threshold)\n",
    "cov = coverage_manual(test_filtered, preds_train_df, train_matrix, threshold=threshold)\n",
    "\n",
    "print(f\"Precision@{k_top}: {precision:.4f}\")\n",
    "print(f\"Recall@{k_top}:    {recall:.4f}\")\n",
    "print(f\"Coverage:     {cov:.4f} ({cov*100:.2f}% del catálogo)\")\n",
    "\n",
    "if precision + recall > 0:\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    print(f\"F1-Score:     {f1:.4f}\")\n",
    "\n",
    "\n",
    "# ========== EJEMPLOS: PREDICCIONES VS REALES ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EJEMPLOS: PREDICCIONES VS RATINGS REALES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Usuario':<10} {'Película':<10} {'Real':<8} {'Predicho':<10} {'Error':<8}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Seleccionar muestra aleatoria\n",
    "sample_size = min(20, len(test_filtered))\n",
    "sample_indices = random.sample(range(len(test_filtered)), sample_size)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    row = test_filtered.iloc[idx]\n",
    "    user = row['userId']\n",
    "    movie = row['movieId']\n",
    "    true_rating = row['rating']\n",
    "    pred_rating = preds_train_df.loc[user, movie]\n",
    "    error = abs(true_rating - pred_rating)\n",
    "    \n",
    "    print(f\"{user:<10} {movie:<10} {true_rating:<8.1f} {pred_rating:<10.2f} {error:<8.2f}\")\n",
    "\n",
    "\n",
    "# ========== DISTRIBUCIÓN DE ERRORES ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DISTRIBUCIÓN DE ERRORES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calcular todos los errores\n",
    "errors = []\n",
    "for _, row in test_filtered.iterrows():\n",
    "    user = row['userId']\n",
    "    movie = row['movieId']\n",
    "    true_rating = row['rating']\n",
    "    pred_rating = preds_train_df.loc[user, movie]\n",
    "    error = abs(true_rating - pred_rating)\n",
    "    errors.append(error)\n",
    "\n",
    "print(f\"Error promedio:      {np.mean(errors):.4f}\")\n",
    "print(f\"Error mediano:       {np.median(errors):.4f}\")\n",
    "print(f\"Error máximo:        {np.max(errors):.4f}\")\n",
    "print(f\"Desviación estándar: {np.std(errors):.4f}\")\n",
    "\n",
    "print(\"\\nDistribución de errores absolutos:\")\n",
    "bins = [0, 0.5, 1.0, 1.5, 2.0, 5.0]\n",
    "for i in range(len(bins)-1):\n",
    "    count = sum(1 for e in errors if bins[i] <= e < bins[i+1])\n",
    "    percentage = (count / len(errors)) * 100\n",
    "    print(f\"  {bins[i]:.1f} - {bins[i+1]:.1f}: {count:6d} ({percentage:5.2f}%)\")\n",
    "\n",
    "\n",
    "# ========== ANÁLISIS POR USUARIO ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TOP 5 USUARIOS CON MEJOR/PEOR PREDICCIÓN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calcular error promedio por usuario\n",
    "user_errors = defaultdict(list)\n",
    "for _, row in test_filtered.iterrows():\n",
    "    user = row['userId']\n",
    "    movie = row['movieId']\n",
    "    true_rating = row['rating']\n",
    "    pred_rating = preds_train_df.loc[user, movie]\n",
    "    error = abs(true_rating - pred_rating)\n",
    "    user_errors[user].append(error)\n",
    "\n",
    "# Promediar errores por usuario\n",
    "user_avg_errors = {user: np.mean(errors) for user, errors in user_errors.items() if len(errors) >= 5}\n",
    "\n",
    "if user_avg_errors:\n",
    "    # Mejores usuarios (menor error)\n",
    "    best_users = sorted(user_avg_errors.items(), key=lambda x: x[1])[:5]\n",
    "    print(\"\\nMejor predicción (menor error):\")\n",
    "    for user, avg_error in best_users:\n",
    "        n_ratings = len(user_errors[user])\n",
    "        print(f\"  Usuario {user}: Error promedio = {avg_error:.4f} ({n_ratings} ratings)\")\n",
    "    \n",
    "    # Peores usuarios (mayor error)\n",
    "    worst_users = sorted(user_avg_errors.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    print(\"\\nPeor predicción (mayor error):\")\n",
    "    for user, avg_error in worst_users:\n",
    "        n_ratings = len(user_errors[user])\n",
    "        print(f\"  Usuario {user}: Error promedio = {avg_error:.4f} ({n_ratings} ratings)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54284b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecutando validación cruzada con 5 folds...\n",
      "\n",
      "Fold 1/5\n",
      "  RMSE: 0.9633\n",
      "  MAE: 0.7631\n",
      "\n",
      "Fold 2/5\n",
      "  RMSE: 0.9570\n",
      "  MAE: 0.7575\n",
      "\n",
      "Fold 3/5\n",
      "  RMSE: 0.9580\n",
      "  MAE: 0.7580\n",
      "\n",
      "Fold 4/5\n",
      "  RMSE: 0.9596\n",
      "  MAE: 0.7592\n",
      "\n",
      "Fold 5/5\n",
      "  RMSE: 0.9584\n",
      "  MAE: 0.7583\n",
      "\n",
      "==================================================\n",
      "RESULTADOS DE VALIDACIÓN CRUZADA\n",
      "==================================================\n",
      "RMSE promedio: 0.9592 (± 0.0022)\n",
      "MAE promedio:  0.7592 (± 0.0020)\n",
      "\n",
      "RMSE por fold: ['0.9633', '0.9570', '0.9580', '0.9596', '0.9584']\n",
      "MAE por fold:  ['0.7631', '0.7575', '0.7580', '0.7592', '0.7583']\n"
     ]
    }
   ],
   "source": [
    "# --- Validación Cruzada K-Fold ---\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.sparse.linalg import svds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Configurar K-Fold\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Almacenar métricas de cada fold\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "\n",
    "print(f\"Ejecutando validación cruzada con {n_splits} folds...\\n\")\n",
    "\n",
    "# Iterar sobre los folds\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(ratings), 1):\n",
    "    print(f\"Fold {fold}/{n_splits}\")\n",
    "    \n",
    "    # Dividir datos\n",
    "    train_ratings = ratings.iloc[train_idx]\n",
    "    test_ratings = ratings.iloc[test_idx]\n",
    "    \n",
    "    # Crear matriz usuario-película\n",
    "    train_matrix = train_ratings.pivot(index='userId', columns='movieId', values='rating')\n",
    "    \n",
    "    # Calcular medias SOLO sobre valores reales (ignorando NaN)\n",
    "    user_means = train_matrix.mean(axis=1).fillna(0)\n",
    "    \n",
    "    # Normalizar ANTES de rellenar\n",
    "    matrix_norm = train_matrix.sub(user_means, axis=0)\n",
    "    \n",
    "    # Rellenar con 0 (desviación desconocida)\n",
    "    matrix_norm_filled = matrix_norm.fillna(0).values\n",
    "    \n",
    "    # SVD\n",
    "    U, sigma, Vt = svds(matrix_norm_filled, k=20)\n",
    "    sigma = np.diag(sigma)\n",
    "    \n",
    "    # Reconstruir y desnormalizar\n",
    "    all_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_means.values.reshape(-1, 1)\n",
    "    \n",
    "    # Limitar predicciones al rango válido\n",
    "    all_predicted_ratings = np.clip(all_predicted_ratings, 1, 5)\n",
    "    \n",
    "    preds_train_df = pd.DataFrame(\n",
    "        all_predicted_ratings, \n",
    "        columns=train_matrix.columns, \n",
    "        index=train_matrix.index\n",
    "    )\n",
    "    \n",
    "    # Evaluar en test\n",
    "    test_filtered = test_ratings[\n",
    "        test_ratings['movieId'].isin(preds_train_df.columns) & \n",
    "        test_ratings['userId'].isin(preds_train_df.index)\n",
    "    ]\n",
    "    \n",
    "    preds = []\n",
    "    for _, row in test_filtered.iterrows():\n",
    "        user = row['userId']\n",
    "        movie = row['movieId']\n",
    "        pred = preds_train_df.loc[user, movie]\n",
    "        preds.append(pred)\n",
    "    \n",
    "    if len(preds) > 0:\n",
    "        rmse = np.sqrt(mean_squared_error(test_filtered['rating'], preds))\n",
    "        mae = mean_absolute_error(test_filtered['rating'], preds)\n",
    "        \n",
    "        rmse_scores.append(rmse)\n",
    "        mae_scores.append(mae)\n",
    "        \n",
    "        print(f\"  RMSE: {rmse:.4f}\")\n",
    "        print(f\"  MAE: {mae:.4f}\\n\")\n",
    "\n",
    "# Resultados finales\n",
    "print(\"=\"*50)\n",
    "print(\"RESULTADOS DE VALIDACIÓN CRUZADA\")\n",
    "print(\"=\"*50)\n",
    "print(f\"RMSE promedio: {np.mean(rmse_scores):.4f} (± {np.std(rmse_scores):.4f})\")\n",
    "print(f\"MAE promedio:  {np.mean(mae_scores):.4f} (± {np.std(mae_scores):.4f})\")\n",
    "print(\"\\nRMSE por fold:\", [f\"{score:.4f}\" for score in rmse_scores])\n",
    "print(\"MAE por fold: \", [f\"{score:.4f}\" for score in mae_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18c48691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SURPRISE SVD - VALIDACIÓN CRUZADA (5-Folds)\n",
      "============================================================\n",
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8718  0.8689  0.8682  0.8714  0.8716  0.8704  0.0015  \n",
      "MAE (testset)     0.6849  0.6831  0.6823  0.6847  0.6843  0.6839  0.0010  \n",
      "Fit time          3.33    3.30    3.41    3.28    3.47    3.36    0.07    \n",
      "Test time         0.59    0.71    1.00    0.71    0.99    0.80    0.16    \n",
      "\n",
      "============================================================\n",
      "RESULTADOS FINALES\n",
      "============================================================\n",
      "RMSE promedio: 0.8704 (± 0.0015)\n",
      "MAE promedio:  0.6839 (± 0.0010)\n"
     ]
    }
   ],
   "source": [
    "# ========== VALIDACIÓN CON SURPRISE SVD ==========\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "import numpy as np\n",
    "\n",
    "# Hiperparámetros configurables\n",
    "n_factors = 50         # Número de factores latentes\n",
    "n_epochs = 20          # Número de épocas de entrenamiento\n",
    "lr_all = 0.005         # Tasa de aprendizaje (learning rate)\n",
    "reg_all = 0.02         # Parámetro de regularización\n",
    "cv_folds = 5           # Cantidad de folds para validación cruzada\n",
    "\n",
    "# Crear dataset para Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Configurar modelo SVD con gradient descent y regularización\n",
    "algo = SVD(n_factors=n_factors, n_epochs=n_epochs, lr_all=lr_all, reg_all=reg_all)\n",
    "\n",
    "# Validación cruzada\n",
    "print(\"=\" * 60)\n",
    "print(\"SURPRISE SVD - VALIDACIÓN CRUZADA (5-Folds)\")\n",
    "print(\"=\" * 60)\n",
    "results = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=cv_folds, verbose=True)\n",
    "\n",
    "# Resultados finales\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESULTADOS FINALES\")\n",
    "print(\"=\" * 60)\n",
    "print(f'RMSE promedio: {np.mean(results[\"test_rmse\"]):.4f} (± {np.std(results[\"test_rmse\"]):.4f})')\n",
    "print(f'MAE promedio:  {np.mean(results[\"test_mae\"]):.4f} (± {np.std(results[\"test_mae\"]):.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94045d95",
   "metadata": {},
   "source": [
    "## Modelo Surprise SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97efe34d",
   "metadata": {},
   "source": [
    "### Evaluación de Surprise SVD con split 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a751b5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SURPRISE SVD - SPLIT TEST (80/20)\n",
      "============================================================\n",
      "RMSE: 0.8714\n",
      "MAE:  0.6840\n"
     ]
    }
   ],
   "source": [
    "# ========== EVALUACIÓN SURPRISE SVD - SPLIT 80/20 ==========\n",
    "from surprise import SVD, Dataset, Reader, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Hiperparámetros (usar los mismos definidos anteriormente)\n",
    "# n_factors, n_epochs, lr_all, reg_all\n",
    "\n",
    "# Crear dataset para Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Split 80/20\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar modelo SVD\n",
    "algo = SVD(n_factors=n_factors, n_epochs=n_epochs, lr_all=lr_all, reg_all=reg_all)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Predecir en test set\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Calcular métricas\n",
    "print(\"=\" * 60)\n",
    "print(\"SURPRISE SVD - SPLIT TEST (80/20)\")\n",
    "print(\"=\" * 60)\n",
    "rmse = accuracy.rmse(predictions, verbose=True)\n",
    "mae = accuracy.mae(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf509ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MÉTRICAS ADICIONALES\n",
      "============================================================\n",
      "Precision@10: 0.6807\n",
      "Recall@10:    0.6339\n",
      "Coverage:     0.7657 (76.57% de películas cubiertas)\n",
      "F1-Score:     0.6565\n",
      "\n",
      "============================================================\n",
      "EJEMPLOS: PREDICCIONES VS RATINGS REALES\n",
      "============================================================\n",
      "Usuario    Película   Real     Predicho   Error   \n",
      "------------------------------------------------------------\n",
      "2156       1527       3.0      4.24       1.24    \n",
      "3201       3681       5.0      4.57       0.43    \n",
      "2700       1611       3.0      2.82       0.18    \n",
      "910        1008       3.0      3.37       0.37    \n",
      "2513       1304       4.0      4.52       0.52    \n",
      "1776       2991       3.0      3.60       0.60    \n",
      "4411       3052       5.0      3.95       1.05    \n",
      "4906       1687       4.0      3.33       0.67    \n",
      "3742       1288       4.0      4.55       0.55    \n",
      "5668       2046       4.0      3.96       0.04    \n",
      "5265       1719       3.0      4.06       1.06    \n",
      "5765       2001       3.0      3.20       0.20    \n",
      "5134       457        3.0      3.60       0.60    \n",
      "3732       2857       4.0      3.52       0.48    \n",
      "5880       1641       4.0      3.19       0.81    \n",
      "3775       3072       3.0      3.42       0.42    \n",
      "4190       1639       2.0      3.18       1.18    \n",
      "1465       1983       2.0      2.65       0.65    \n",
      "2140       1198       5.0      4.14       0.86    \n",
      "4662       3175       3.0      2.94       0.06    \n",
      "\n",
      "============================================================\n",
      "DISTRIBUCIÓN DE ERRORES\n",
      "============================================================\n",
      "Error promedio:     0.6840\n",
      "Error mediano:      0.5692\n",
      "Error máximo:       4.0000\n",
      "Desviación estándar: 0.5399\n",
      "\n",
      "Distribución de errores absolutos:\n",
      "  0.0 - 0.5:  89462 (44.72%)\n",
      "  0.5 - 1.0:  63010 (31.50%)\n",
      "  1.0 - 1.5:  30941 (15.47%)\n",
      "  1.5 - 2.0:  11272 ( 5.63%)\n",
      "  2.0 - 5.0:   5357 ( 2.68%)\n"
     ]
    }
   ],
   "source": [
    "# ========== MÉTRICAS ADICIONALES: PRECISION, RECALL, COVERAGE ==========\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    \"\"\"\n",
    "    Calcula Precision@K y Recall@K\n",
    "    \n",
    "    Args:\n",
    "        predictions: predicciones de Surprise\n",
    "        k: número de recomendaciones top-k\n",
    "        threshold: rating mínimo para considerar relevante\n",
    "    \"\"\"\n",
    "    # Diccionarios por usuario\n",
    "    user_est_true = defaultdict(list)\n",
    "    \n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        # Ordenar por predicción descendente\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        # Top-k predicciones\n",
    "        top_k = user_ratings[:k]\n",
    "        \n",
    "        # Relevantes en top-k\n",
    "        n_rel_and_rec_k = sum((true_r >= threshold) for (_, true_r) in top_k)\n",
    "        \n",
    "        # Total de relevantes para este usuario\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        \n",
    "        # Precision@K\n",
    "        precisions.append(n_rel_and_rec_k / k if k != 0 else 0)\n",
    "        \n",
    "        # Recall@K\n",
    "        recalls.append(n_rel_and_rec_k / n_rel if n_rel != 0 else 0)\n",
    "    \n",
    "    precision = np.mean(precisions)\n",
    "    recall = np.mean(recalls)\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "\n",
    "def coverage(predictions, trainset, threshold=3.5):\n",
    "    \"\"\"\n",
    "    Calcula el coverage: porcentaje de ítems que el modelo recomienda\n",
    "    \"\"\"\n",
    "    # Todos los ítems en el dataset\n",
    "    all_items = set(trainset.all_items())\n",
    "    \n",
    "    # Ítems recomendados (con predicción >= threshold)\n",
    "    recommended_items = set()\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        if est >= threshold:\n",
    "            recommended_items.add(iid)\n",
    "    \n",
    "    coverage_score = len(recommended_items) / len(all_items)\n",
    "    return coverage_score\n",
    "\n",
    "\n",
    "# ========== CALCULAR MÉTRICAS ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MÉTRICAS ADICIONALES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Precision y Recall\n",
    "precision, recall = precision_recall_at_k(predictions, k=10, threshold=3.5)\n",
    "print(f\"Precision@10: {precision:.4f}\")\n",
    "print(f\"Recall@10:    {recall:.4f}\")\n",
    "\n",
    "# Coverage\n",
    "cov = coverage(predictions, trainset, threshold=3.5)\n",
    "print(f\"Coverage:     {cov:.4f} ({cov*100:.2f}% de películas cubiertas)\")\n",
    "\n",
    "# F1-Score (combinación de Precision y Recall)\n",
    "if precision + recall > 0:\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    print(f\"F1-Score:     {f1:.4f}\")\n",
    "\n",
    "\n",
    "# ========== COMPARACIÓN: PREDICCIONES VS REALES ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EJEMPLOS: PREDICCIONES VS RATINGS REALES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Usuario':<10} {'Película':<10} {'Real':<8} {'Predicho':<10} {'Error':<8}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Mostrar 20 ejemplos aleatorios\n",
    "import random\n",
    "sample_predictions = random.sample(predictions, min(20, len(predictions)))\n",
    "\n",
    "for uid, iid, true_r, est, _ in sample_predictions:\n",
    "    error = abs(true_r - est)\n",
    "    print(f\"{uid:<10} {iid:<10} {true_r:<8.1f} {est:<10.2f} {error:<8.2f}\")\n",
    "\n",
    "# ========== ESTADÍSTICAS DE ERROR ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DISTRIBUCIÓN DE ERRORES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "errors = [abs(true_r - est) for (_, _, true_r, est, _) in predictions]\n",
    "print(f\"Error promedio:     {np.mean(errors):.4f}\")\n",
    "print(f\"Error mediano:      {np.median(errors):.4f}\")\n",
    "print(f\"Error máximo:       {np.max(errors):.4f}\")\n",
    "print(f\"Desviación estándar: {np.std(errors):.4f}\")\n",
    "\n",
    "# Distribución de errores por rangos\n",
    "print(\"\\nDistribución de errores absolutos:\")\n",
    "bins = [0, 0.5, 1.0, 1.5, 2.0, 5.0]\n",
    "for i in range(len(bins)-1):\n",
    "    count = sum(bins[i] <= e < bins[i+1] for e in errors)\n",
    "    percentage = (count / len(errors)) * 100\n",
    "    print(f\"  {bins[i]:.1f} - {bins[i+1]:.1f}: {count:6d} ({percentage:5.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "558c4b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Surprise SVD guardado en svd_surprise.pkl\n"
     ]
    }
   ],
   "source": [
    "# Exportar modelo Surprise SVD entrenado (después de fit/trainset)\n",
    "import pickle\n",
    "with open('svd_surprise.pkl', 'wb') as f:\n",
    "    pickle.dump(algo, f)\n",
    "print('Modelo Surprise SVD guardado en svd_surprise.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ml1m",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
