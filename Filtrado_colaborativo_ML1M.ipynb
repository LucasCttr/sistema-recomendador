{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5fe0b4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de usuarios únicos: 6040\n",
      "Cantidad de películas únicas: 3706\n",
      "Formato de ratings (valores únicos): [1, 2, 3, 4, 5]\n",
      "Ejemplo de ratings: [5, 3, 3, 4, 5, 3, 5, 5, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "# Exploración inicial del dataset MovieLens 1M\n",
    "print('Cantidad de usuarios únicos:', ratings['userId'].nunique())\n",
    "print('Cantidad de películas únicas:', ratings['movieId'].nunique())\n",
    "print('Formato de ratings (valores únicos):', sorted(ratings['rating'].unique()))\n",
    "print('Ejemplo de ratings:', ratings['rating'].head(10).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddacbabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas de ratings: ['userId', 'movieId', 'rating', 'timestamp']\n",
      "Tipos de datos:\n",
      "userId       int64\n",
      "movieId      int64\n",
      "rating       int64\n",
      "timestamp    int64\n",
      "dtype: object\n",
      "Primeras filas:\n",
      "   userId  movieId  rating  timestamp\n",
      "0       1     1193       5  978300760\n",
      "1       1      661       3  978302109\n",
      "2       1      914       3  978301968\n",
      "3       1     3408       4  978300275\n",
      "4       1     2355       5  978824291\n"
     ]
    }
   ],
   "source": [
    "# Formato de la tabla ratings\n",
    "print('Columnas de ratings:', ratings.columns.tolist())\n",
    "print('Tipos de datos:')\n",
    "print(ratings.dtypes)\n",
    "print('Primeras filas:')\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ebfa9c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings por película (media, min, max): 269.88909875876953 1 3428\n",
      "Ratings por usuario (media, min, max): 165.5975165562914 20 2314\n"
     ]
    }
   ],
   "source": [
    "# Cantidad de ratings por película y por usuario\n",
    "print('Ratings por película (media, min, max):',\n",
    "      ratings['movieId'].value_counts().mean(),\n",
    "      ratings['movieId'].value_counts().min(),\n",
    "      ratings['movieId'].value_counts().max())\n",
    "print('Ratings por usuario (media, min, max):',\n",
    "      ratings['userId'].value_counts().mean(),\n",
    "      ratings['userId'].value_counts().min(),\n",
    "      ratings['userId'].value_counts().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03539d43",
   "metadata": {},
   "source": [
    "# Sistema de recomendación con MovieLens 1M\n",
    "Este notebook  se basa en el entrenamiento y validacion de un modelo de filtrado colaborativo usando SVD sobre el dataset MovieLens 1M."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b7b3f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘ml-1m.zip’ already there; not retrieving.\n",
      "\n",
      "Archive:  ml-1m.zip\n"
     ]
    }
   ],
   "source": [
    "# Descargar y descomprimir MovieLens 1M\n",
    "!wget -nc https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "!unzip -n ml-1m.zip -d ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "510cfe0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1     1193       5  978300760\n",
       "1       1      661       3  978302109\n",
       "2       1      914       3  978301968\n",
       "3       1     3408       4  978300275\n",
       "4       1     2355       5  978824291"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Cargar ratings\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep='::', engine='python', names=['userId', 'movieId', 'rating', 'timestamp'])\n",
    "# Cargar películas\n",
    "movies = pd.read_csv('ml-1m/movies.dat', sep='::', engine='python', names=['movieId', 'title', 'genres'], encoding='latin-1')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ddeddefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear matriz usuario-película\n",
    "user_movie_matrix = ratings.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
    "user_movie_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "256b4209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE promedio: 0.9592\n",
      "MAE promedio: 0.7592\n"
     ]
    }
   ],
   "source": [
    "# validación Split Data\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.sparse.linalg import svds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "cv_folds = 5\n",
    "kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "\n",
    "for train_idx, test_idx in kf.split(ratings):\n",
    "    train_ratings = ratings.iloc[train_idx]\n",
    "    test_ratings = ratings.iloc[test_idx]\n",
    "    \n",
    "    # Crear matriz usuario-película\n",
    "    train_matrix = train_ratings.pivot(index='userId', columns='movieId', values='rating')\n",
    "    \n",
    "    # CLAVE: Calcular medias SOLO sobre valores reales (ignorando NaN)\n",
    "    user_means = train_matrix.mean(axis=1).fillna(0)\n",
    "    \n",
    "    # Normalizar ANTES de rellenar\n",
    "    matrix_norm = train_matrix.sub(user_means, axis=0)\n",
    "    \n",
    "    # AHORA sí rellenar con 0 (representa \"desviación desconocida\")\n",
    "    matrix_norm_filled = matrix_norm.fillna(0).values\n",
    "    \n",
    "    # SVD\n",
    "    U, sigma, Vt = svds(matrix_norm_filled, k=20)\n",
    "    sigma = np.diag(sigma)\n",
    "    \n",
    "    # Reconstruir y desnormalizar\n",
    "    all_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_means.values.reshape(-1, 1)\n",
    "    \n",
    "    # Limitar predicciones al rango válido\n",
    "    all_predicted_ratings = np.clip(all_predicted_ratings, 1, 5)\n",
    "    \n",
    "    preds_train_df = pd.DataFrame(\n",
    "        all_predicted_ratings, \n",
    "        columns=train_matrix.columns, \n",
    "        index=train_matrix.index\n",
    "    )\n",
    "    \n",
    "    # Evaluar en test\n",
    "    test_filtered = test_ratings[\n",
    "        test_ratings['movieId'].isin(preds_train_df.columns) & \n",
    "        test_ratings['userId'].isin(preds_train_df.index)\n",
    "    ]\n",
    "    \n",
    "    preds = []\n",
    "    for _, row in test_filtered.iterrows():\n",
    "        user = row['userId']\n",
    "        movie = row['movieId']\n",
    "        pred = preds_train_df.loc[user, movie]\n",
    "        preds.append(pred)\n",
    "    \n",
    "    if len(preds) > 0:\n",
    "        rmse = np.sqrt(mean_squared_error(test_filtered['rating'], preds))\n",
    "        mae = mean_absolute_error(test_filtered['rating'], preds)\n",
    "        rmse_scores.append(rmse)\n",
    "        mae_scores.append(mae)\n",
    "\n",
    "print(f'RMSE promedio: {np.mean(rmse_scores):.4f}')\n",
    "print(f'MAE promedio: {np.mean(mae_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "774a245d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SVD MANUAL - MÉTRICAS ADICIONALES\n",
      "============================================================\n",
      "Precision@10: 0.6796\n",
      "Recall@10:    0.6371\n",
      "Coverage:     0.8980 (89.80% del catálogo)\n",
      "F1-Score:     0.6576\n",
      "\n",
      "============================================================\n",
      "EJEMPLOS: PREDICCIONES VS RATINGS REALES\n",
      "============================================================\n",
      "Usuario    Película   Real     Predicho   Error   \n",
      "------------------------------------------------------------\n",
      "3922       63         4.0      2.62       1.38    \n",
      "3659       246        5.0      4.27       0.73    \n",
      "5763       1060       4.0      3.60       0.40    \n",
      "1701       1327       1.0      3.28       2.28    \n",
      "3055       512        1.0      3.54       2.54    \n",
      "268        2000       4.0      3.86       0.14    \n",
      "4824       1090       5.0      3.89       1.11    \n",
      "1794       1479       2.0      2.21       0.21    \n",
      "551        1834       4.0      3.75       0.25    \n",
      "3732       829        4.0      3.49       0.51    \n",
      "4262       2174       4.0      3.60       0.40    \n",
      "2586       1077       4.0      4.05       0.05    \n",
      "5795       1918       1.0      1.08       0.08    \n",
      "1607       2716       4.0      3.23       0.77    \n",
      "4333       2571       5.0      4.60       0.40    \n",
      "1793       1882       1.0      2.82       1.82    \n",
      "889        2239       3.0      2.94       0.06    \n",
      "5972       2713       3.0      3.53       0.53    \n",
      "2106       709        2.0      2.10       0.10    \n",
      "5593       1129       5.0      4.48       0.52    \n",
      "\n",
      "============================================================\n",
      "DISTRIBUCIÓN DE ERRORES\n",
      "============================================================\n",
      "Error promedio:      0.7583\n",
      "Error mediano:       0.6395\n",
      "Error máximo:        3.8865\n",
      "Desviación estándar: 0.5861\n",
      "\n",
      "Distribución de errores absolutos:\n",
      "  0.0 - 0.5:  80771 (40.38%)\n",
      "  0.5 - 1.0:  61495 (30.75%)\n",
      "  1.0 - 1.5:  35293 (17.65%)\n",
      "  1.5 - 2.0:  14362 ( 7.18%)\n",
      "  2.0 - 5.0:   8084 ( 4.04%)\n",
      "\n",
      "============================================================\n",
      "TOP 5 USUARIOS CON MEJOR/PEOR PREDICCIÓN\n",
      "============================================================\n",
      "\n",
      "Mejor predicción (menor error):\n",
      "  Usuario 3598: Error promedio = 0.0196 (13 ratings)\n",
      "  Usuario 5037: Error promedio = 0.0437 (17 ratings)\n",
      "  Usuario 4614: Error promedio = 0.0596 (6 ratings)\n",
      "  Usuario 2339: Error promedio = 0.0607 (7 ratings)\n",
      "  Usuario 283: Error promedio = 0.1429 (7 ratings)\n",
      "\n",
      "Peor predicción (mayor error):\n",
      "  Usuario 2432: Error promedio = 2.2580 (6 ratings)\n",
      "  Usuario 4761: Error promedio = 2.1243 (8 ratings)\n",
      "  Usuario 2982: Error promedio = 2.0776 (6 ratings)\n",
      "  Usuario 1270: Error promedio = 1.7710 (9 ratings)\n",
      "  Usuario 5828: Error promedio = 1.7480 (5 ratings)\n"
     ]
    }
   ],
   "source": [
    "# ========== MÉTRICAS ADICIONALES PARA SVD MANUAL ==========\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Configuración\n",
    "k_top = 10\n",
    "threshold = 3.5\n",
    "\n",
    "# Volver a ejecutar UN FOLD para obtener predicciones\n",
    "# (usamos el último fold del cross-validation anterior)\n",
    "train_ratings = ratings.iloc[train_idx]\n",
    "test_ratings = ratings.iloc[test_idx]\n",
    "\n",
    "# Crear matriz usuario-película\n",
    "train_matrix = train_ratings.pivot(index='userId', columns='movieId', values='rating')\n",
    "user_means = train_matrix.mean(axis=1).fillna(0)\n",
    "matrix_norm = train_matrix.sub(user_means, axis=0)\n",
    "matrix_norm_filled = matrix_norm.fillna(0).values\n",
    "\n",
    "# SVD\n",
    "U, sigma, Vt = svds(matrix_norm_filled, k=20)\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "# Reconstruir\n",
    "all_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_means.values.reshape(-1, 1)\n",
    "all_predicted_ratings = np.clip(all_predicted_ratings, 1, 5)\n",
    "\n",
    "preds_train_df = pd.DataFrame(\n",
    "    all_predicted_ratings, \n",
    "    columns=train_matrix.columns, \n",
    "    index=train_matrix.index\n",
    ")\n",
    "\n",
    "# Filtrar test\n",
    "test_filtered = test_ratings[\n",
    "    test_ratings['movieId'].isin(preds_train_df.columns) & \n",
    "    test_ratings['userId'].isin(preds_train_df.index)\n",
    "]\n",
    "\n",
    "\n",
    "# ========== FUNCIONES DE EVALUACIÓN ==========\n",
    "def precision_recall_at_k_manual(test_filtered, preds_df, k=10, threshold=3.5):\n",
    "    \"\"\"Calcula Precision@K y Recall@K para SVD manual\"\"\"\n",
    "    \n",
    "    # Agrupar por usuario\n",
    "    user_predictions = defaultdict(list)\n",
    "    \n",
    "    for _, row in test_filtered.iterrows():\n",
    "        user = row['userId']\n",
    "        movie = row['movieId']\n",
    "        true_rating = row['rating']\n",
    "        pred_rating = preds_df.loc[user, movie]\n",
    "        \n",
    "        user_predictions[user].append((pred_rating, true_rating))\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    for user, predictions in user_predictions.items():\n",
    "        # Ordenar por predicción descendente\n",
    "        predictions_sorted = sorted(predictions, key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        # Top-k\n",
    "        top_k = predictions_sorted[:k]\n",
    "        \n",
    "        # Relevantes en top-k\n",
    "        n_rel_and_rec_k = sum(1 for (_, true_r) in top_k if true_r >= threshold)\n",
    "        \n",
    "        # Total relevantes\n",
    "        n_rel = sum(1 for (_, true_r) in predictions if true_r >= threshold)\n",
    "        \n",
    "        # Precision y Recall\n",
    "        if k > 0:\n",
    "            precisions.append(n_rel_and_rec_k / k)\n",
    "        if n_rel > 0:\n",
    "            recalls.append(n_rel_and_rec_k / n_rel)\n",
    "    \n",
    "    return np.mean(precisions) if precisions else 0, np.mean(recalls) if recalls else 0\n",
    "\n",
    "\n",
    "def coverage_manual(test_filtered, preds_df, train_matrix, threshold=3.5):\n",
    "    \"\"\"Calcula coverage para SVD manual\"\"\"\n",
    "    \n",
    "    # Todas las películas en el dataset de entrenamiento\n",
    "    all_movies = set(train_matrix.columns)\n",
    "    \n",
    "    # Películas recomendadas (con predicción >= threshold)\n",
    "    recommended_movies = set()\n",
    "    \n",
    "    for _, row in test_filtered.iterrows():\n",
    "        user = row['userId']\n",
    "        movie = row['movieId']\n",
    "        pred_rating = preds_df.loc[user, movie]\n",
    "        \n",
    "        if pred_rating >= threshold:\n",
    "            recommended_movies.add(movie)\n",
    "    \n",
    "    coverage_score = len(recommended_movies) / len(all_movies) if len(all_movies) > 0 else 0\n",
    "    return coverage_score\n",
    "\n",
    "\n",
    "# ========== CALCULAR MÉTRICAS ==========\n",
    "print(\"=\" * 60)\n",
    "print(\"SVD MANUAL - MÉTRICAS ADICIONALES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "precision, recall = precision_recall_at_k_manual(test_filtered, preds_train_df, k=k_top, threshold=threshold)\n",
    "cov = coverage_manual(test_filtered, preds_train_df, train_matrix, threshold=threshold)\n",
    "\n",
    "print(f\"Precision@{k_top}: {precision:.4f}\")\n",
    "print(f\"Recall@{k_top}:    {recall:.4f}\")\n",
    "print(f\"Coverage:     {cov:.4f} ({cov*100:.2f}% del catálogo)\")\n",
    "\n",
    "if precision + recall > 0:\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    print(f\"F1-Score:     {f1:.4f}\")\n",
    "\n",
    "\n",
    "# ========== EJEMPLOS: PREDICCIONES VS REALES ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EJEMPLOS: PREDICCIONES VS RATINGS REALES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Usuario':<10} {'Película':<10} {'Real':<8} {'Predicho':<10} {'Error':<8}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Seleccionar muestra aleatoria\n",
    "sample_size = min(20, len(test_filtered))\n",
    "sample_indices = random.sample(range(len(test_filtered)), sample_size)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    row = test_filtered.iloc[idx]\n",
    "    user = row['userId']\n",
    "    movie = row['movieId']\n",
    "    true_rating = row['rating']\n",
    "    pred_rating = preds_train_df.loc[user, movie]\n",
    "    error = abs(true_rating - pred_rating)\n",
    "    \n",
    "    print(f\"{user:<10} {movie:<10} {true_rating:<8.1f} {pred_rating:<10.2f} {error:<8.2f}\")\n",
    "\n",
    "\n",
    "# ========== DISTRIBUCIÓN DE ERRORES ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DISTRIBUCIÓN DE ERRORES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calcular todos los errores\n",
    "errors = []\n",
    "for _, row in test_filtered.iterrows():\n",
    "    user = row['userId']\n",
    "    movie = row['movieId']\n",
    "    true_rating = row['rating']\n",
    "    pred_rating = preds_train_df.loc[user, movie]\n",
    "    error = abs(true_rating - pred_rating)\n",
    "    errors.append(error)\n",
    "\n",
    "print(f\"Error promedio:      {np.mean(errors):.4f}\")\n",
    "print(f\"Error mediano:       {np.median(errors):.4f}\")\n",
    "print(f\"Error máximo:        {np.max(errors):.4f}\")\n",
    "print(f\"Desviación estándar: {np.std(errors):.4f}\")\n",
    "\n",
    "print(\"\\nDistribución de errores absolutos:\")\n",
    "bins = [0, 0.5, 1.0, 1.5, 2.0, 5.0]\n",
    "for i in range(len(bins)-1):\n",
    "    count = sum(1 for e in errors if bins[i] <= e < bins[i+1])\n",
    "    percentage = (count / len(errors)) * 100\n",
    "    print(f\"  {bins[i]:.1f} - {bins[i+1]:.1f}: {count:6d} ({percentage:5.2f}%)\")\n",
    "\n",
    "\n",
    "# ========== ANÁLISIS POR USUARIO ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TOP 5 USUARIOS CON MEJOR/PEOR PREDICCIÓN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calcular error promedio por usuario\n",
    "user_errors = defaultdict(list)\n",
    "for _, row in test_filtered.iterrows():\n",
    "    user = row['userId']\n",
    "    movie = row['movieId']\n",
    "    true_rating = row['rating']\n",
    "    pred_rating = preds_train_df.loc[user, movie]\n",
    "    error = abs(true_rating - pred_rating)\n",
    "    user_errors[user].append(error)\n",
    "\n",
    "# Promediar errores por usuario\n",
    "user_avg_errors = {user: np.mean(errors) for user, errors in user_errors.items() if len(errors) >= 5}\n",
    "\n",
    "if user_avg_errors:\n",
    "    # Mejores usuarios (menor error)\n",
    "    best_users = sorted(user_avg_errors.items(), key=lambda x: x[1])[:5]\n",
    "    print(\"\\nMejor predicción (menor error):\")\n",
    "    for user, avg_error in best_users:\n",
    "        n_ratings = len(user_errors[user])\n",
    "        print(f\"  Usuario {user}: Error promedio = {avg_error:.4f} ({n_ratings} ratings)\")\n",
    "    \n",
    "    # Peores usuarios (mayor error)\n",
    "    worst_users = sorted(user_avg_errors.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    print(\"\\nPeor predicción (mayor error):\")\n",
    "    for user, avg_error in worst_users:\n",
    "        n_ratings = len(user_errors[user])\n",
    "        print(f\"  Usuario {user}: Error promedio = {avg_error:.4f} ({n_ratings} ratings)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "54284b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecutando validación cruzada con 5 folds...\n",
      "\n",
      "Fold 1/5\n",
      "  RMSE: 0.9633\n",
      "  MAE: 0.7631\n",
      "\n",
      "Fold 2/5\n",
      "  RMSE: 0.9570\n",
      "  MAE: 0.7575\n",
      "\n",
      "Fold 3/5\n",
      "  RMSE: 0.9580\n",
      "  MAE: 0.7580\n",
      "\n",
      "Fold 4/5\n",
      "  RMSE: 0.9596\n",
      "  MAE: 0.7592\n",
      "\n",
      "Fold 5/5\n",
      "  RMSE: 0.9584\n",
      "  MAE: 0.7583\n",
      "\n",
      "==================================================\n",
      "RESULTADOS DE VALIDACIÓN CRUZADA\n",
      "==================================================\n",
      "RMSE promedio: 0.9592 (± 0.0022)\n",
      "MAE promedio:  0.7592 (± 0.0020)\n",
      "\n",
      "RMSE por fold: ['0.9633', '0.9570', '0.9580', '0.9596', '0.9584']\n",
      "MAE por fold:  ['0.7631', '0.7575', '0.7580', '0.7592', '0.7583']\n"
     ]
    }
   ],
   "source": [
    "# --- Validación Cruzada K-Fold ---\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.sparse.linalg import svds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Configurar K-Fold\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Almacenar métricas de cada fold\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "\n",
    "print(f\"Ejecutando validación cruzada con {n_splits} folds...\\n\")\n",
    "\n",
    "# Iterar sobre los folds\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(ratings), 1):\n",
    "    print(f\"Fold {fold}/{n_splits}\")\n",
    "    \n",
    "    # Dividir datos\n",
    "    train_ratings = ratings.iloc[train_idx]\n",
    "    test_ratings = ratings.iloc[test_idx]\n",
    "    \n",
    "    # Crear matriz usuario-película\n",
    "    train_matrix = train_ratings.pivot(index='userId', columns='movieId', values='rating')\n",
    "    \n",
    "    # Calcular medias SOLO sobre valores reales (ignorando NaN)\n",
    "    user_means = train_matrix.mean(axis=1).fillna(0)\n",
    "    \n",
    "    # Normalizar ANTES de rellenar\n",
    "    matrix_norm = train_matrix.sub(user_means, axis=0)\n",
    "    \n",
    "    # Rellenar con 0 (desviación desconocida)\n",
    "    matrix_norm_filled = matrix_norm.fillna(0).values\n",
    "    \n",
    "    # SVD\n",
    "    U, sigma, Vt = svds(matrix_norm_filled, k=20)\n",
    "    sigma = np.diag(sigma)\n",
    "    \n",
    "    # Reconstruir y desnormalizar\n",
    "    all_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_means.values.reshape(-1, 1)\n",
    "    \n",
    "    # Limitar predicciones al rango válido\n",
    "    all_predicted_ratings = np.clip(all_predicted_ratings, 1, 5)\n",
    "    \n",
    "    preds_train_df = pd.DataFrame(\n",
    "        all_predicted_ratings, \n",
    "        columns=train_matrix.columns, \n",
    "        index=train_matrix.index\n",
    "    )\n",
    "    \n",
    "    # Evaluar en test\n",
    "    test_filtered = test_ratings[\n",
    "        test_ratings['movieId'].isin(preds_train_df.columns) & \n",
    "        test_ratings['userId'].isin(preds_train_df.index)\n",
    "    ]\n",
    "    \n",
    "    preds = []\n",
    "    for _, row in test_filtered.iterrows():\n",
    "        user = row['userId']\n",
    "        movie = row['movieId']\n",
    "        pred = preds_train_df.loc[user, movie]\n",
    "        preds.append(pred)\n",
    "    \n",
    "    if len(preds) > 0:\n",
    "        rmse = np.sqrt(mean_squared_error(test_filtered['rating'], preds))\n",
    "        mae = mean_absolute_error(test_filtered['rating'], preds)\n",
    "        \n",
    "        rmse_scores.append(rmse)\n",
    "        mae_scores.append(mae)\n",
    "        \n",
    "        print(f\"  RMSE: {rmse:.4f}\")\n",
    "        print(f\"  MAE: {mae:.4f}\\n\")\n",
    "\n",
    "# Resultados finales\n",
    "print(\"=\"*50)\n",
    "print(\"RESULTADOS DE VALIDACIÓN CRUZADA\")\n",
    "print(\"=\"*50)\n",
    "print(f\"RMSE promedio: {np.mean(rmse_scores):.4f} (± {np.std(rmse_scores):.4f})\")\n",
    "print(f\"MAE promedio:  {np.mean(mae_scores):.4f} (± {np.std(mae_scores):.4f})\")\n",
    "print(\"\\nRMSE por fold:\", [f\"{score:.4f}\" for score in rmse_scores])\n",
    "print(\"MAE por fold: \", [f\"{score:.4f}\" for score in mae_scores])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bff846",
   "metadata": {},
   "source": [
    "## Validación con Surprise (SVD y matrices dispersas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "18c48691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SURPRISE SVD - VALIDACIÓN CRUZADA (5-Folds)\n",
      "============================================================\n",
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8708  0.8728  0.8697  0.8700  0.8708  0.8708  0.0011  \n",
      "MAE (testset)     0.6844  0.6849  0.6828  0.6838  0.6840  0.6840  0.0007  \n",
      "Fit time          3.33    3.30    3.50    3.73    4.19    3.61    0.33    \n",
      "Test time         0.64    0.64    0.65    0.74    0.71    0.68    0.04    \n",
      "\n",
      "============================================================\n",
      "RESULTADOS FINALES\n",
      "============================================================\n",
      "RMSE promedio: 0.8708 (± 0.0011)\n",
      "MAE promedio:  0.6840 (± 0.0007)\n"
     ]
    }
   ],
   "source": [
    "# ========== VALIDACIÓN CON SURPRISE SVD ==========\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "import numpy as np\n",
    "\n",
    "# Hiperparámetros configurables\n",
    "n_factors = 50         # Número de factores latentes\n",
    "n_epochs = 20          # Número de épocas de entrenamiento\n",
    "lr_all = 0.005         # Tasa de aprendizaje (learning rate)\n",
    "reg_all = 0.02         # Parámetro de regularización\n",
    "cv_folds = 5           # Cantidad de folds para validación cruzada\n",
    "\n",
    "# Crear dataset para Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Configurar modelo SVD con gradient descent y regularización\n",
    "algo = SVD(n_factors=n_factors, n_epochs=n_epochs, lr_all=lr_all, reg_all=reg_all)\n",
    "\n",
    "# Validación cruzada\n",
    "print(\"=\" * 60)\n",
    "print(\"SURPRISE SVD - VALIDACIÓN CRUZADA (5-Folds)\")\n",
    "print(\"=\" * 60)\n",
    "results = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=cv_folds, verbose=True)\n",
    "\n",
    "# Resultados finales\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESULTADOS FINALES\")\n",
    "print(\"=\" * 60)\n",
    "print(f'RMSE promedio: {np.mean(results[\"test_rmse\"]):.4f} (± {np.std(results[\"test_rmse\"]):.4f})')\n",
    "print(f'MAE promedio:  {np.mean(results[\"test_mae\"]):.4f} (± {np.std(results[\"test_mae\"]):.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97efe34d",
   "metadata": {},
   "source": [
    "### Evaluación de Surprise SVD con split 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a751b5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SURPRISE SVD - SPLIT TEST (80/20)\n",
      "============================================================\n",
      "RMSE: 0.8709\n",
      "MAE:  0.6838\n"
     ]
    }
   ],
   "source": [
    "# ========== EVALUACIÓN SURPRISE SVD - SPLIT 80/20 ==========\n",
    "from surprise import SVD, Dataset, Reader, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Hiperparámetros (usar los mismos definidos anteriormente)\n",
    "# n_factors, n_epochs, lr_all, reg_all\n",
    "\n",
    "# Crear dataset para Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Split 80/20\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar modelo SVD\n",
    "algo = SVD(n_factors=n_factors, n_epochs=n_epochs, lr_all=lr_all, reg_all=reg_all)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Predecir en test set\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Calcular métricas\n",
    "print(\"=\" * 60)\n",
    "print(\"SURPRISE SVD - SPLIT TEST (80/20)\")\n",
    "print(\"=\" * 60)\n",
    "rmse = accuracy.rmse(predictions, verbose=True)\n",
    "mae = accuracy.mae(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bf509ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MÉTRICAS ADICIONALES\n",
      "============================================================\n",
      "Precision@10: 0.6821\n",
      "Recall@10:    0.6348\n",
      "Coverage:     0.7671 (76.71% de películas cubiertas)\n",
      "F1-Score:     0.6576\n",
      "\n",
      "============================================================\n",
      "EJEMPLOS: PREDICCIONES VS RATINGS REALES\n",
      "============================================================\n",
      "Usuario    Película   Real     Predicho   Error   \n",
      "------------------------------------------------------------\n",
      "4085       3044       4.0      4.06       0.06    \n",
      "2453       147        4.0      3.50       0.50    \n",
      "2175       2404       3.0      3.26       0.26    \n",
      "2590       1603       3.0      2.90       0.10    \n",
      "204        3300       1.0      3.31       2.31    \n",
      "117        1037       3.0      3.41       0.41    \n",
      "3151       2184       5.0      4.02       0.98    \n",
      "3170       2028       5.0      4.09       0.91    \n",
      "2918       733        2.0      2.75       0.75    \n",
      "5736       2010       4.0      4.14       0.14    \n",
      "3365       3600       4.0      3.47       0.53    \n",
      "3726       552        3.0      3.42       0.42    \n",
      "1839       3785       4.0      4.00       0.00    \n",
      "2393       1251       4.0      3.85       0.15    \n",
      "2611       339        1.0      2.49       1.49    \n",
      "5501       1267       5.0      4.62       0.38    \n",
      "4381       489        1.0      2.48       1.48    \n",
      "530        968        3.0      3.72       0.72    \n",
      "1191       898        5.0      4.52       0.48    \n",
      "3885       1252       4.0      4.88       0.88    \n",
      "\n",
      "============================================================\n",
      "DISTRIBUCIÓN DE ERRORES\n",
      "============================================================\n",
      "Error promedio:     0.6838\n",
      "Error mediano:      0.5683\n",
      "Error máximo:       4.0000\n",
      "Desviación estándar: 0.5393\n",
      "\n",
      "Distribución de errores absolutos:\n",
      "  0.0 - 0.5:  89452 (44.72%)\n",
      "  0.5 - 1.0:  62955 (31.47%)\n",
      "  1.0 - 1.5:  31068 (15.53%)\n",
      "  1.5 - 2.0:  11231 ( 5.61%)\n",
      "  2.0 - 5.0:   5336 ( 2.67%)\n"
     ]
    }
   ],
   "source": [
    "# ========== MÉTRICAS ADICIONALES: PRECISION, RECALL, COVERAGE ==========\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    \"\"\"\n",
    "    Calcula Precision@K y Recall@K\n",
    "    \n",
    "    Args:\n",
    "        predictions: predicciones de Surprise\n",
    "        k: número de recomendaciones top-k\n",
    "        threshold: rating mínimo para considerar relevante\n",
    "    \"\"\"\n",
    "    # Diccionarios por usuario\n",
    "    user_est_true = defaultdict(list)\n",
    "    \n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        # Ordenar por predicción descendente\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        # Top-k predicciones\n",
    "        top_k = user_ratings[:k]\n",
    "        \n",
    "        # Relevantes en top-k\n",
    "        n_rel_and_rec_k = sum((true_r >= threshold) for (_, true_r) in top_k)\n",
    "        \n",
    "        # Total de relevantes para este usuario\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        \n",
    "        # Precision@K\n",
    "        precisions.append(n_rel_and_rec_k / k if k != 0 else 0)\n",
    "        \n",
    "        # Recall@K\n",
    "        recalls.append(n_rel_and_rec_k / n_rel if n_rel != 0 else 0)\n",
    "    \n",
    "    precision = np.mean(precisions)\n",
    "    recall = np.mean(recalls)\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "\n",
    "def coverage(predictions, trainset, threshold=3.5):\n",
    "    \"\"\"\n",
    "    Calcula el coverage: porcentaje de ítems que el modelo recomienda\n",
    "    \"\"\"\n",
    "    # Todos los ítems en el dataset\n",
    "    all_items = set(trainset.all_items())\n",
    "    \n",
    "    # Ítems recomendados (con predicción >= threshold)\n",
    "    recommended_items = set()\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        if est >= threshold:\n",
    "            recommended_items.add(iid)\n",
    "    \n",
    "    coverage_score = len(recommended_items) / len(all_items)\n",
    "    return coverage_score\n",
    "\n",
    "\n",
    "# ========== CALCULAR MÉTRICAS ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MÉTRICAS ADICIONALES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Precision y Recall\n",
    "precision, recall = precision_recall_at_k(predictions, k=10, threshold=3.5)\n",
    "print(f\"Precision@10: {precision:.4f}\")\n",
    "print(f\"Recall@10:    {recall:.4f}\")\n",
    "\n",
    "# Coverage\n",
    "cov = coverage(predictions, trainset, threshold=3.5)\n",
    "print(f\"Coverage:     {cov:.4f} ({cov*100:.2f}% de películas cubiertas)\")\n",
    "\n",
    "# F1-Score (combinación de Precision y Recall)\n",
    "if precision + recall > 0:\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    print(f\"F1-Score:     {f1:.4f}\")\n",
    "\n",
    "\n",
    "# ========== COMPARACIÓN: PREDICCIONES VS REALES ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EJEMPLOS: PREDICCIONES VS RATINGS REALES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Usuario':<10} {'Película':<10} {'Real':<8} {'Predicho':<10} {'Error':<8}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Mostrar 20 ejemplos aleatorios\n",
    "import random\n",
    "sample_predictions = random.sample(predictions, min(20, len(predictions)))\n",
    "\n",
    "for uid, iid, true_r, est, _ in sample_predictions:\n",
    "    error = abs(true_r - est)\n",
    "    print(f\"{uid:<10} {iid:<10} {true_r:<8.1f} {est:<10.2f} {error:<8.2f}\")\n",
    "\n",
    "# ========== ESTADÍSTICAS DE ERROR ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DISTRIBUCIÓN DE ERRORES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "errors = [abs(true_r - est) for (_, _, true_r, est, _) in predictions]\n",
    "print(f\"Error promedio:     {np.mean(errors):.4f}\")\n",
    "print(f\"Error mediano:      {np.median(errors):.4f}\")\n",
    "print(f\"Error máximo:       {np.max(errors):.4f}\")\n",
    "print(f\"Desviación estándar: {np.std(errors):.4f}\")\n",
    "\n",
    "# Distribución de errores por rangos\n",
    "print(\"\\nDistribución de errores absolutos:\")\n",
    "bins = [0, 0.5, 1.0, 1.5, 2.0, 5.0]\n",
    "for i in range(len(bins)-1):\n",
    "    count = sum(bins[i] <= e < bins[i+1] for e in errors)\n",
    "    percentage = (count / len(errors)) * 100\n",
    "    print(f\"  {bins[i]:.1f} - {bins[i+1]:.1f}: {count:6d} ({percentage:5.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ml1m",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
