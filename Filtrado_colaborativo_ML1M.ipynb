{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03539d43",
   "metadata": {},
   "source": [
    "# Sistema de recomendación con MovieLens 1M\n",
    "Este notebook  se basa en el entrenamiento y validacion de un modelo de filtrado colaborativo usando SVD sobre el dataset MovieLens 1M."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3b7b3f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘ml-1m.zip’ already there; not retrieving.\n",
      "\n",
      "Archive:  ml-1m.zip\n"
     ]
    }
   ],
   "source": [
    "# Descargar y descomprimir MovieLens 1M\n",
    "!wget -nc https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "!unzip -n ml-1m.zip -d ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "510cfe0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1     1193       5  978300760\n",
       "1       1      661       3  978302109\n",
       "2       1      914       3  978301968\n",
       "3       1     3408       4  978300275\n",
       "4       1     2355       5  978824291"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Cargar ratings\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep='::', engine='python', names=['userId', 'movieId', 'rating', 'timestamp'])\n",
    "# Cargar películas\n",
    "movies = pd.read_csv('ml-1m/movies.dat', sep='::', engine='python', names=['movieId', 'title', 'genres'], encoding='latin-1')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8760d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formato de la tabla ratings\n",
    "print('Columnas de ratings:', ratings.columns.tolist())\n",
    "print('Tipos de datos:')\n",
    "print(ratings.dtypes)\n",
    "print('Primeras filas:')\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab374f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de ratings por película y por usuario\n",
    "print('Ratings por película (media, min, max):',\n",
    "      ratings['movieId'].value_counts().mean(),\n",
    "      ratings['movieId'].value_counts().min(),\n",
    "      ratings['movieId'].value_counts().max())\n",
    "print('Ratings por usuario (media, min, max):',\n",
    "      ratings['userId'].value_counts().mean(),\n",
    "      ratings['userId'].value_counts().min(),\n",
    "      ratings['userId'].value_counts().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bf9586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploración inicial del dataset MovieLens 1M\n",
    "print('Cantidad de usuarios únicos:', ratings['userId'].nunique())\n",
    "print('Cantidad de películas únicas:', ratings['movieId'].nunique())\n",
    "print('Formato de ratings (valores únicos):', sorted(ratings['rating'].unique()))\n",
    "print('Ejemplo de ratings:', ratings['rating'].head(10).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8376b7",
   "metadata": {},
   "source": [
    "## Modelo SVD Tradicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "256b4209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE promedio: 0.9592\n",
      "MAE promedio: 0.7592\n"
     ]
    }
   ],
   "source": [
    "# validación Split Data\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.sparse.linalg import svds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "cv_folds = 5\n",
    "kf = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "\n",
    "for train_idx, test_idx in kf.split(ratings):\n",
    "    train_ratings = ratings.iloc[train_idx]\n",
    "    test_ratings = ratings.iloc[test_idx]\n",
    "    \n",
    "    # Crear matriz usuario-película\n",
    "    train_matrix = train_ratings.pivot(index='userId', columns='movieId', values='rating')\n",
    "    \n",
    "    # CLAVE: Calcular medias SOLO sobre valores reales (ignorando NaN)\n",
    "    user_means = train_matrix.mean(axis=1).fillna(0)\n",
    "    \n",
    "    # Normalizar ANTES de rellenar\n",
    "    matrix_norm = train_matrix.sub(user_means, axis=0)\n",
    "    \n",
    "    # AHORA sí rellenar con 0 (representa \"desviación desconocida\")\n",
    "    matrix_norm_filled = matrix_norm.fillna(0).values\n",
    "    \n",
    "    # SVD\n",
    "    U, sigma, Vt = svds(matrix_norm_filled, k=20)\n",
    "    sigma = np.diag(sigma)\n",
    "    \n",
    "    # Reconstruir y desnormalizar\n",
    "    all_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_means.values.reshape(-1, 1)\n",
    "    \n",
    "    # Limitar predicciones al rango válido\n",
    "    all_predicted_ratings = np.clip(all_predicted_ratings, 1, 5)\n",
    "    \n",
    "    preds_train_df = pd.DataFrame(\n",
    "        all_predicted_ratings, \n",
    "        columns=train_matrix.columns, \n",
    "        index=train_matrix.index\n",
    "    )\n",
    "    \n",
    "    # Evaluar en test\n",
    "    test_filtered = test_ratings[\n",
    "        test_ratings['movieId'].isin(preds_train_df.columns) & \n",
    "        test_ratings['userId'].isin(preds_train_df.index)\n",
    "    ]\n",
    "    \n",
    "    preds = []\n",
    "    for _, row in test_filtered.iterrows():\n",
    "        user = row['userId']\n",
    "        movie = row['movieId']\n",
    "        pred = preds_train_df.loc[user, movie]\n",
    "        preds.append(pred)\n",
    "    \n",
    "    if len(preds) > 0:\n",
    "        rmse = np.sqrt(mean_squared_error(test_filtered['rating'], preds))\n",
    "        mae = mean_absolute_error(test_filtered['rating'], preds)\n",
    "        rmse_scores.append(rmse)\n",
    "        mae_scores.append(mae)\n",
    "\n",
    "print(f'RMSE promedio: {np.mean(rmse_scores):.4f}')\n",
    "print(f'MAE promedio: {np.mean(mae_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "774a245d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SVD MANUAL - MÉTRICAS ADICIONALES\n",
      "============================================================\n",
      "Precision@10: 0.8250\n",
      "Recall@10:    0.5968\n",
      "Coverage:     0.9244 (92.44% del catálogo)\n",
      "F1-Score:     0.6926\n",
      "\n",
      "============================================================\n",
      "EJEMPLOS: PREDICCIONES VS RATINGS REALES\n",
      "============================================================\n",
      "Usuario    Película   Real     Predicho   Error   \n",
      "------------------------------------------------------------\n",
      "2271       3093       3.0      4.08       1.08    \n",
      "4455       2600       4.0      3.71       0.29    \n",
      "5964       3396       5.0      4.25       0.75    \n",
      "3591       3408       4.0      3.79       0.21    \n",
      "4909       1196       4.0      3.89       0.11    \n",
      "4024       1225       5.0      3.41       1.59    \n",
      "4772       908        4.0      4.23       0.23    \n",
      "3690       3044       3.0      2.99       0.01    \n",
      "4329       2762       5.0      4.08       0.92    \n",
      "2059       1617       3.0      3.51       0.51    \n",
      "4312       3256       3.0      3.52       0.52    \n",
      "3266       1103       5.0      4.37       0.63    \n",
      "3539       523        3.0      4.01       1.01    \n",
      "33         2664       5.0      3.74       1.26    \n",
      "1788       2291       3.0      4.09       1.09    \n",
      "3390       2080       5.0      4.20       0.80    \n",
      "4207       2262       3.0      4.19       1.19    \n",
      "2643       1092       3.0      3.53       0.53    \n",
      "937        3020       4.0      3.77       0.23    \n",
      "2601       2291       5.0      3.60       1.40    \n",
      "\n",
      "============================================================\n",
      "DISTRIBUCIÓN DE ERRORES\n",
      "============================================================\n",
      "Error promedio:      0.7583\n",
      "Error mediano:       0.6395\n",
      "Error máximo:        3.8865\n",
      "Desviación estándar: 0.5861\n",
      "\n",
      "Distribución de errores absolutos:\n",
      "  0.0 - 0.5:  80771 (40.38%)\n",
      "  0.5 - 1.0:  61495 (30.75%)\n",
      "  1.0 - 1.5:  35293 (17.65%)\n",
      "  1.5 - 2.0:  14362 ( 7.18%)\n",
      "  2.0 - 5.0:   8084 ( 4.04%)\n",
      "\n",
      "============================================================\n",
      "TOP 5 USUARIOS CON MEJOR/PEOR PREDICCIÓN\n",
      "============================================================\n",
      "\n",
      "Mejor predicción (menor error):\n",
      "  Usuario 3598: Error promedio = 0.0196 (13 ratings)\n",
      "  Usuario 5037: Error promedio = 0.0437 (17 ratings)\n",
      "  Usuario 4614: Error promedio = 0.0596 (6 ratings)\n",
      "  Usuario 2339: Error promedio = 0.0607 (7 ratings)\n",
      "  Usuario 283: Error promedio = 0.1429 (7 ratings)\n",
      "\n",
      "Peor predicción (mayor error):\n",
      "  Usuario 2432: Error promedio = 2.2580 (6 ratings)\n",
      "  Usuario 4761: Error promedio = 2.1243 (8 ratings)\n",
      "  Usuario 2982: Error promedio = 2.0776 (6 ratings)\n",
      "  Usuario 1270: Error promedio = 1.7710 (9 ratings)\n",
      "  Usuario 5828: Error promedio = 1.7480 (5 ratings)\n"
     ]
    }
   ],
   "source": [
    "# ========== MÉTRICAS ADICIONALES PARA SVD MANUAL ==========\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Configuración\n",
    "k_top = 10\n",
    "threshold = 3\n",
    "\n",
    "# Volver a ejecutar UN FOLD para obtener predicciones\n",
    "# (usamos el último fold del cross-validation anterior)\n",
    "train_ratings = ratings.iloc[train_idx]\n",
    "test_ratings = ratings.iloc[test_idx]\n",
    "\n",
    "# Crear matriz usuario-película\n",
    "train_matrix = train_ratings.pivot(index='userId', columns='movieId', values='rating')\n",
    "user_means = train_matrix.mean(axis=1).fillna(0)\n",
    "matrix_norm = train_matrix.sub(user_means, axis=0)\n",
    "matrix_norm_filled = matrix_norm.fillna(0).values\n",
    "\n",
    "# SVD\n",
    "U, sigma, Vt = svds(matrix_norm_filled, k=20)\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "# Reconstruir\n",
    "all_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_means.values.reshape(-1, 1)\n",
    "all_predicted_ratings = np.clip(all_predicted_ratings, 1, 5)\n",
    "\n",
    "preds_train_df = pd.DataFrame(\n",
    "    all_predicted_ratings, \n",
    "    columns=train_matrix.columns, \n",
    "    index=train_matrix.index\n",
    ")\n",
    "\n",
    "# Filtrar test\n",
    "test_filtered = test_ratings[\n",
    "    test_ratings['movieId'].isin(preds_train_df.columns) & \n",
    "    test_ratings['userId'].isin(preds_train_df.index)\n",
    "]\n",
    "\n",
    "\n",
    "# ========== FUNCIONES DE EVALUACIÓN ==========\n",
    "def precision_recall_at_k_manual(test_filtered, preds_df, k=10, threshold=3.5):\n",
    "    \"\"\"Calcula Precision@K y Recall@K para SVD manual\"\"\"\n",
    "    \n",
    "    # Agrupar por usuario\n",
    "    user_predictions = defaultdict(list)\n",
    "    \n",
    "    for _, row in test_filtered.iterrows():\n",
    "        user = row['userId']\n",
    "        movie = row['movieId']\n",
    "        true_rating = row['rating']\n",
    "        pred_rating = preds_df.loc[user, movie]\n",
    "        \n",
    "        user_predictions[user].append((pred_rating, true_rating))\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    for user, predictions in user_predictions.items():\n",
    "        # Ordenar por predicción descendente\n",
    "        predictions_sorted = sorted(predictions, key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        # Top-k\n",
    "        top_k = predictions_sorted[:k]\n",
    "        \n",
    "        # Relevantes en top-k\n",
    "        n_rel_and_rec_k = sum(1 for (_, true_r) in top_k if true_r >= threshold)\n",
    "        \n",
    "        # Total relevantes\n",
    "        n_rel = sum(1 for (_, true_r) in predictions if true_r >= threshold)\n",
    "        \n",
    "        # Precision y Recall\n",
    "        if k > 0:\n",
    "            precisions.append(n_rel_and_rec_k / k)\n",
    "        if n_rel > 0:\n",
    "            recalls.append(n_rel_and_rec_k / n_rel)\n",
    "    \n",
    "    return np.mean(precisions) if precisions else 0, np.mean(recalls) if recalls else 0\n",
    "\n",
    "\n",
    "def coverage_manual(test_filtered, preds_df, train_matrix, threshold=3.5):\n",
    "    \"\"\"Calcula coverage para SVD manual\"\"\"\n",
    "    \n",
    "    # Todas las películas en el dataset de entrenamiento\n",
    "    all_movies = set(train_matrix.columns)\n",
    "    \n",
    "    # Películas recomendadas (con predicción >= threshold)\n",
    "    recommended_movies = set()\n",
    "    \n",
    "    for _, row in test_filtered.iterrows():\n",
    "        user = row['userId']\n",
    "        movie = row['movieId']\n",
    "        pred_rating = preds_df.loc[user, movie]\n",
    "        \n",
    "        if pred_rating >= threshold:\n",
    "            recommended_movies.add(movie)\n",
    "    \n",
    "    coverage_score = len(recommended_movies) / len(all_movies) if len(all_movies) > 0 else 0\n",
    "    return coverage_score\n",
    "\n",
    "\n",
    "# ========== CALCULAR MÉTRICAS ==========\n",
    "print(\"=\" * 60)\n",
    "print(\"SVD MANUAL - MÉTRICAS ADICIONALES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "precision, recall = precision_recall_at_k_manual(test_filtered, preds_train_df, k=k_top, threshold=threshold)\n",
    "cov = coverage_manual(test_filtered, preds_train_df, train_matrix, threshold=threshold)\n",
    "\n",
    "print(f\"Precision@{k_top}: {precision:.4f}\")\n",
    "print(f\"Recall@{k_top}:    {recall:.4f}\")\n",
    "print(f\"Coverage:     {cov:.4f} ({cov*100:.2f}% del catálogo)\")\n",
    "\n",
    "if precision + recall > 0:\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    print(f\"F1-Score:     {f1:.4f}\")\n",
    "\n",
    "\n",
    "# ========== EJEMPLOS: PREDICCIONES VS REALES ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EJEMPLOS: PREDICCIONES VS RATINGS REALES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Usuario':<10} {'Película':<10} {'Real':<8} {'Predicho':<10} {'Error':<8}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Seleccionar muestra aleatoria\n",
    "sample_size = min(20, len(test_filtered))\n",
    "sample_indices = random.sample(range(len(test_filtered)), sample_size)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    row = test_filtered.iloc[idx]\n",
    "    user = row['userId']\n",
    "    movie = row['movieId']\n",
    "    true_rating = row['rating']\n",
    "    pred_rating = preds_train_df.loc[user, movie]\n",
    "    error = abs(true_rating - pred_rating)\n",
    "    \n",
    "    print(f\"{user:<10} {movie:<10} {true_rating:<8.1f} {pred_rating:<10.2f} {error:<8.2f}\")\n",
    "\n",
    "\n",
    "# ========== DISTRIBUCIÓN DE ERRORES ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DISTRIBUCIÓN DE ERRORES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calcular todos los errores\n",
    "errors = []\n",
    "for _, row in test_filtered.iterrows():\n",
    "    user = row['userId']\n",
    "    movie = row['movieId']\n",
    "    true_rating = row['rating']\n",
    "    pred_rating = preds_train_df.loc[user, movie]\n",
    "    error = abs(true_rating - pred_rating)\n",
    "    errors.append(error)\n",
    "\n",
    "print(f\"Error promedio:      {np.mean(errors):.4f}\")\n",
    "print(f\"Error mediano:       {np.median(errors):.4f}\")\n",
    "print(f\"Error máximo:        {np.max(errors):.4f}\")\n",
    "print(f\"Desviación estándar: {np.std(errors):.4f}\")\n",
    "\n",
    "print(\"\\nDistribución de errores absolutos:\")\n",
    "bins = [0, 0.5, 1.0, 1.5, 2.0, 5.0]\n",
    "for i in range(len(bins)-1):\n",
    "    count = sum(1 for e in errors if bins[i] <= e < bins[i+1])\n",
    "    percentage = (count / len(errors)) * 100\n",
    "    print(f\"  {bins[i]:.1f} - {bins[i+1]:.1f}: {count:6d} ({percentage:5.2f}%)\")\n",
    "\n",
    "\n",
    "# ========== ANÁLISIS POR USUARIO ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TOP 5 USUARIOS CON MEJOR/PEOR PREDICCIÓN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calcular error promedio por usuario\n",
    "user_errors = defaultdict(list)\n",
    "for _, row in test_filtered.iterrows():\n",
    "    user = row['userId']\n",
    "    movie = row['movieId']\n",
    "    true_rating = row['rating']\n",
    "    pred_rating = preds_train_df.loc[user, movie]\n",
    "    error = abs(true_rating - pred_rating)\n",
    "    user_errors[user].append(error)\n",
    "\n",
    "# Promediar errores por usuario\n",
    "user_avg_errors = {user: np.mean(errors) for user, errors in user_errors.items() if len(errors) >= 5}\n",
    "\n",
    "if user_avg_errors:\n",
    "    # Mejores usuarios (menor error)\n",
    "    best_users = sorted(user_avg_errors.items(), key=lambda x: x[1])[:5]\n",
    "    print(\"\\nMejor predicción (menor error):\")\n",
    "    for user, avg_error in best_users:\n",
    "        n_ratings = len(user_errors[user])\n",
    "        print(f\"  Usuario {user}: Error promedio = {avg_error:.4f} ({n_ratings} ratings)\")\n",
    "    \n",
    "    # Peores usuarios (mayor error)\n",
    "    worst_users = sorted(user_avg_errors.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    print(\"\\nPeor predicción (mayor error):\")\n",
    "    for user, avg_error in worst_users:\n",
    "        n_ratings = len(user_errors[user])\n",
    "        print(f\"  Usuario {user}: Error promedio = {avg_error:.4f} ({n_ratings} ratings)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "54284b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecutando validación cruzada con 5 folds...\n",
      "\n",
      "Fold 1/5\n",
      "  RMSE: 0.9633\n",
      "  MAE: 0.7631\n",
      "\n",
      "Fold 2/5\n",
      "  RMSE: 0.9570\n",
      "  MAE: 0.7575\n",
      "\n",
      "Fold 3/5\n",
      "  RMSE: 0.9580\n",
      "  MAE: 0.7580\n",
      "\n",
      "Fold 4/5\n",
      "  RMSE: 0.9596\n",
      "  MAE: 0.7592\n",
      "\n",
      "Fold 5/5\n",
      "  RMSE: 0.9584\n",
      "  MAE: 0.7583\n",
      "\n",
      "==================================================\n",
      "RESULTADOS DE VALIDACIÓN CRUZADA\n",
      "==================================================\n",
      "RMSE promedio: 0.9592 (± 0.0022)\n",
      "MAE promedio:  0.7592 (± 0.0020)\n",
      "\n",
      "RMSE por fold: ['0.9633', '0.9570', '0.9580', '0.9596', '0.9584']\n",
      "MAE por fold:  ['0.7631', '0.7575', '0.7580', '0.7592', '0.7583']\n"
     ]
    }
   ],
   "source": [
    "# --- Validación Cruzada K-Fold ---\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.sparse.linalg import svds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Configurar K-Fold\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Almacenar métricas de cada fold\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "\n",
    "print(f\"Ejecutando validación cruzada con {n_splits} folds...\\n\")\n",
    "\n",
    "# Iterar sobre los folds\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(ratings), 1):\n",
    "    print(f\"Fold {fold}/{n_splits}\")\n",
    "    \n",
    "    # Dividir datos\n",
    "    train_ratings = ratings.iloc[train_idx]\n",
    "    test_ratings = ratings.iloc[test_idx]\n",
    "    \n",
    "    # Crear matriz usuario-película\n",
    "    train_matrix = train_ratings.pivot(index='userId', columns='movieId', values='rating')\n",
    "    \n",
    "    # Calcular medias SOLO sobre valores reales (ignorando NaN)\n",
    "    user_means = train_matrix.mean(axis=1).fillna(0)\n",
    "    \n",
    "    # Normalizar ANTES de rellenar\n",
    "    matrix_norm = train_matrix.sub(user_means, axis=0)\n",
    "    \n",
    "    # Rellenar con 0 (desviación desconocida)\n",
    "    matrix_norm_filled = matrix_norm.fillna(0).values\n",
    "    \n",
    "    # SVD\n",
    "    U, sigma, Vt = svds(matrix_norm_filled, k=20)\n",
    "    sigma = np.diag(sigma)\n",
    "    \n",
    "    # Reconstruir y desnormalizar\n",
    "    all_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_means.values.reshape(-1, 1)\n",
    "    \n",
    "    # Limitar predicciones al rango válido\n",
    "    all_predicted_ratings = np.clip(all_predicted_ratings, 1, 5)\n",
    "    \n",
    "    preds_train_df = pd.DataFrame(\n",
    "        all_predicted_ratings, \n",
    "        columns=train_matrix.columns, \n",
    "        index=train_matrix.index\n",
    "    )\n",
    "    \n",
    "    # Evaluar en test\n",
    "    test_filtered = test_ratings[\n",
    "        test_ratings['movieId'].isin(preds_train_df.columns) & \n",
    "        test_ratings['userId'].isin(preds_train_df.index)\n",
    "    ]\n",
    "    \n",
    "    preds = []\n",
    "    for _, row in test_filtered.iterrows():\n",
    "        user = row['userId']\n",
    "        movie = row['movieId']\n",
    "        pred = preds_train_df.loc[user, movie]\n",
    "        preds.append(pred)\n",
    "    \n",
    "    if len(preds) > 0:\n",
    "        rmse = np.sqrt(mean_squared_error(test_filtered['rating'], preds))\n",
    "        mae = mean_absolute_error(test_filtered['rating'], preds)\n",
    "        \n",
    "        rmse_scores.append(rmse)\n",
    "        mae_scores.append(mae)\n",
    "        \n",
    "        print(f\"  RMSE: {rmse:.4f}\")\n",
    "        print(f\"  MAE: {mae:.4f}\\n\")\n",
    "\n",
    "# Resultados finales\n",
    "print(\"=\"*50)\n",
    "print(\"RESULTADOS DE VALIDACIÓN CRUZADA\")\n",
    "print(\"=\"*50)\n",
    "print(f\"RMSE promedio: {np.mean(rmse_scores):.4f} (± {np.std(rmse_scores):.4f})\")\n",
    "print(f\"MAE promedio:  {np.mean(mae_scores):.4f} (± {np.std(mae_scores):.4f})\")\n",
    "print(\"\\nRMSE por fold:\", [f\"{score:.4f}\" for score in rmse_scores])\n",
    "print(\"MAE por fold: \", [f\"{score:.4f}\" for score in mae_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "18c48691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SURPRISE SVD - VALIDACIÓN CRUZADA (5-Folds)\n",
      "============================================================\n",
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8681  0.8735  0.8714  0.8710  0.8700  0.8708  0.0018  \n",
      "MAE (testset)     0.6816  0.6858  0.6849  0.6839  0.6832  0.6839  0.0015  \n",
      "Fit time          3.50    3.62    3.63    3.61    3.60    3.59    0.05    \n",
      "Test time         0.69    0.69    0.68    0.42    0.70    0.64    0.11    \n",
      "\n",
      "============================================================\n",
      "RESULTADOS FINALES\n",
      "============================================================\n",
      "RMSE promedio: 0.8708 (± 0.0018)\n",
      "MAE promedio:  0.6839 (± 0.0015)\n"
     ]
    }
   ],
   "source": [
    "# ========== VALIDACIÓN CON SURPRISE SVD ==========\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "import numpy as np\n",
    "\n",
    "# Hiperparámetros configurables\n",
    "n_factors = 50         # Número de factores latentes\n",
    "n_epochs = 20          # Número de épocas de entrenamiento\n",
    "lr_all = 0.005         # Tasa de aprendizaje (learning rate)\n",
    "reg_all = 0.02         # Parámetro de regularización\n",
    "cv_folds = 5           # Cantidad de folds para validación cruzada\n",
    "\n",
    "# Crear dataset para Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Configurar modelo SVD con gradient descent y regularización\n",
    "algo = SVD(n_factors=n_factors, n_epochs=n_epochs, lr_all=lr_all, reg_all=reg_all)\n",
    "\n",
    "# Validación cruzada\n",
    "print(\"=\" * 60)\n",
    "print(\"SURPRISE SVD - VALIDACIÓN CRUZADA (5-Folds)\")\n",
    "print(\"=\" * 60)\n",
    "results = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=cv_folds, verbose=True)\n",
    "\n",
    "# Resultados finales\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESULTADOS FINALES\")\n",
    "print(\"=\" * 60)\n",
    "print(f'RMSE promedio: {np.mean(results[\"test_rmse\"]):.4f} (± {np.std(results[\"test_rmse\"]):.4f})')\n",
    "print(f'MAE promedio:  {np.mean(results[\"test_mae\"]):.4f} (± {np.std(results[\"test_mae\"]):.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94045d95",
   "metadata": {},
   "source": [
    "## Modelo Surprise SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97efe34d",
   "metadata": {},
   "source": [
    "### Evaluación de Surprise SVD con split 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a751b5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SURPRISE SVD - SPLIT TEST (80/20)\n",
      "============================================================\n",
      "RMSE: 0.8712\n",
      "MAE:  0.6841\n"
     ]
    }
   ],
   "source": [
    "# ========== EVALUACIÓN SURPRISE SVD - SPLIT 80/20 ==========\n",
    "from surprise import SVD, Dataset, Reader, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Hiperparámetros (usar los mismos definidos anteriormente)\n",
    "# n_factors, n_epochs, lr_all, reg_all\n",
    "\n",
    "# Crear dataset para Surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Split 80/20\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar modelo SVD\n",
    "algo = SVD(n_factors=n_factors, n_epochs=n_epochs, lr_all=lr_all, reg_all=reg_all)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Predecir en test set\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Calcular métricas\n",
    "print(\"=\" * 60)\n",
    "print(\"SURPRISE SVD - SPLIT TEST (80/20)\")\n",
    "print(\"=\" * 60)\n",
    "rmse = accuracy.rmse(predictions, verbose=True)\n",
    "mae = accuracy.mae(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf509ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MÉTRICAS ADICIONALES\n",
      "============================================================\n",
      "Precision@10: 0.6798\n",
      "Recall@10:    0.6338\n",
      "Coverage:     0.7693 (76.93% de películas cubiertas)\n",
      "F1-Score:     0.6560\n",
      "\n",
      "============================================================\n",
      "EJEMPLOS: PREDICCIONES VS RATINGS REALES\n",
      "============================================================\n",
      "Usuario    Película   Real     Predicho   Error   \n",
      "------------------------------------------------------------\n",
      "3833       153        4.0      2.87       1.13    \n",
      "1019       2401       3.0      3.60       0.60    \n",
      "93         2476       4.0      3.23       0.77    \n",
      "3635       2935       5.0      4.39       0.61    \n",
      "311        1704       5.0      4.36       0.64    \n",
      "1737       257        4.0      3.69       0.31    \n",
      "2124       2369       3.0      4.13       1.13    \n",
      "5165       593        5.0      4.95       0.05    \n",
      "3792       1744       3.0      2.27       0.73    \n",
      "1767       2986       1.0      2.02       1.02    \n",
      "3454       3865       4.0      3.04       0.96    \n",
      "1941       1952       2.0      3.45       1.45    \n",
      "3999       2568       1.0      1.74       0.74    \n",
      "587        2300       4.0      3.60       0.40    \n",
      "674        2011       4.0      3.59       0.41    \n",
      "3414       1721       4.0      4.20       0.20    \n",
      "301        2702       4.0      2.82       1.18    \n",
      "2453       3868       4.0      2.72       1.28    \n",
      "6021       1270       4.0      4.03       0.03    \n",
      "2693       1617       4.0      3.83       0.17    \n",
      "\n",
      "============================================================\n",
      "DISTRIBUCIÓN DE ERRORES\n",
      "============================================================\n",
      "Error promedio:     0.6841\n",
      "Error mediano:      0.5701\n",
      "Error máximo:       4.0000\n",
      "Desviación estándar: 0.5395\n",
      "\n",
      "Distribución de errores absolutos:\n",
      "  0.0 - 0.5:  89205 (44.59%)\n",
      "  0.5 - 1.0:  63234 (31.61%)\n",
      "  1.0 - 1.5:  31069 (15.53%)\n",
      "  1.5 - 2.0:  11242 ( 5.62%)\n",
      "  2.0 - 5.0:   5292 ( 2.65%)\n"
     ]
    }
   ],
   "source": [
    "# ========== MÉTRICAS ADICIONALES: PRECISION, RECALL, COVERAGE ==========\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    \"\"\"\n",
    "    Calcula Precision@K y Recall@K\n",
    "    \n",
    "    Args:\n",
    "        predictions: predicciones de Surprise\n",
    "        k: número de recomendaciones top-k\n",
    "        threshold: rating mínimo para considerar relevante\n",
    "    \"\"\"\n",
    "    # Diccionarios por usuario\n",
    "    user_est_true = defaultdict(list)\n",
    "    \n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        # Ordenar por predicción descendente\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        # Top-k predicciones\n",
    "        top_k = user_ratings[:k]\n",
    "        \n",
    "        # Relevantes en top-k\n",
    "        n_rel_and_rec_k = sum((true_r >= threshold) for (_, true_r) in top_k)\n",
    "        \n",
    "        # Total de relevantes para este usuario\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        \n",
    "        # Precision@K\n",
    "        precisions.append(n_rel_and_rec_k / k if k != 0 else 0)\n",
    "        \n",
    "        # Recall@K\n",
    "        recalls.append(n_rel_and_rec_k / n_rel if n_rel != 0 else 0)\n",
    "    \n",
    "    precision = np.mean(precisions)\n",
    "    recall = np.mean(recalls)\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "\n",
    "def coverage(predictions, trainset, threshold=3.5):\n",
    "    \"\"\"\n",
    "    Calcula el coverage: porcentaje de ítems que el modelo recomienda\n",
    "    \"\"\"\n",
    "    # Todos los ítems en el dataset\n",
    "    all_items = set(trainset.all_items())\n",
    "    \n",
    "    # Ítems recomendados (con predicción >= threshold)\n",
    "    recommended_items = set()\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        if est >= threshold:\n",
    "            recommended_items.add(iid)\n",
    "    \n",
    "    coverage_score = len(recommended_items) / len(all_items)\n",
    "    return coverage_score\n",
    "\n",
    "\n",
    "# ========== CALCULAR MÉTRICAS ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MÉTRICAS ADICIONALES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Precision y Recall\n",
    "precision, recall = precision_recall_at_k(predictions, k=10, threshold=3.5)\n",
    "print(f\"Precision@10: {precision:.4f}\")\n",
    "print(f\"Recall@10:    {recall:.4f}\")\n",
    "\n",
    "# Coverage\n",
    "cov = coverage(predictions, trainset, threshold=3.5)\n",
    "print(f\"Coverage:     {cov:.4f} ({cov*100:.2f}% de películas cubiertas)\")\n",
    "\n",
    "# F1-Score (combinación de Precision y Recall)\n",
    "if precision + recall > 0:\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    print(f\"F1-Score:     {f1:.4f}\")\n",
    "\n",
    "\n",
    "# ========== COMPARACIÓN: PREDICCIONES VS REALES ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EJEMPLOS: PREDICCIONES VS RATINGS REALES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Usuario':<10} {'Película':<10} {'Real':<8} {'Predicho':<10} {'Error':<8}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Mostrar 20 ejemplos aleatorios\n",
    "import random\n",
    "sample_predictions = random.sample(predictions, min(20, len(predictions)))\n",
    "\n",
    "for uid, iid, true_r, est, _ in sample_predictions:\n",
    "    error = abs(true_r - est)\n",
    "    print(f\"{uid:<10} {iid:<10} {true_r:<8.1f} {est:<10.2f} {error:<8.2f}\")\n",
    "\n",
    "# ========== ESTADÍSTICAS DE ERROR ==========\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DISTRIBUCIÓN DE ERRORES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "errors = [abs(true_r - est) for (_, _, true_r, est, _) in predictions]\n",
    "print(f\"Error promedio:     {np.mean(errors):.4f}\")\n",
    "print(f\"Error mediano:      {np.median(errors):.4f}\")\n",
    "print(f\"Error máximo:       {np.max(errors):.4f}\")\n",
    "print(f\"Desviación estándar: {np.std(errors):.4f}\")\n",
    "\n",
    "# Distribución de errores por rangos\n",
    "print(\"\\nDistribución de errores absolutos:\")\n",
    "bins = [0, 0.5, 1.0, 1.5, 2.0, 5.0]\n",
    "for i in range(len(bins)-1):\n",
    "    count = sum(bins[i] <= e < bins[i+1] for e in errors)\n",
    "    percentage = (count / len(errors)) * 100\n",
    "    print(f\"  {bins[i]:.1f} - {bins[i+1]:.1f}: {count:6d} ({percentage:5.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_ml1m",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
